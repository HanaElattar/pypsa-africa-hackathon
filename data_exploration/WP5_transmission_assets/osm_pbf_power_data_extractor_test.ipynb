{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script does the following\n",
    "# 1. Downloads OSM files for specified countries from Geofabrik\n",
    "# 2. Filters files for substations and lines\n",
    "# 3. Process and clean data\n",
    "# 4. Exports to CSV\n",
    "# 5. Exports to GeoJson\n",
    "\n",
    "\"\"\"\n",
    "OSM extraction scrpt\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# IMPORTANT: RUN SCRIPT FROM THIS SCRIPTS DIRECTORY i.e data_exploration/ TODO: make more robust\n",
    "# os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "sys.path.append(\"../../scripts\")\n",
    "\n",
    "import logging\n",
    "import shutil\n",
    "\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from esy.osmfilter import run_filter\n",
    "from esy.osmfilter import Node, Relation, Way\n",
    "from esy.osmfilter import osm_info as osm_info\n",
    "from esy.osmfilter import osm_pickle as osm_pickle\n",
    "from iso_country_codes import AFRICA_CC\n",
    "from shapely.geometry import LineString, Point\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# https://gitlab.com/dlr-ve-esy/esy-osmfilter/-/tree/master/\n",
    "\n",
    "\n",
    "# import logging\n",
    "# logging.basicConfig()\n",
    "# logger=logging.getLogger(__name__)\n",
    "# logger.setLevel(logging.INFO)\n",
    "# logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Downloads PBF File for given Country Code\n",
    "\n",
    "\n",
    "def download_pbf(country_code, update):\n",
    "    \"\"\"\n",
    "    Downloads the pbf file from geofabrik for a given country code (see scripts/iso_country_codes.py).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    country_code : str\n",
    "    update : bool\n",
    "        name of the network component\n",
    "        update = true forces re-download of files\n",
    "    \"\"\"\n",
    "    country_name = AFRICA_CC[country_code]\n",
    "    # Filename for geofabrik\n",
    "    geofabrik_filename = f\"{country_name}-latest.osm.pbf\"\n",
    "    # https://download.geofabrik.de/africa/nigeria-latest.osm.pbf\n",
    "    geofabrik_url = f\"https://download.geofabrik.de/africa/{geofabrik_filename}\"\n",
    "    PBF_inputfile = os.path.join(\n",
    "        os.getcwd(), \"data\", \"osm\", \"pbf\", geofabrik_filename\n",
    "    )  # Input filepath\n",
    "\n",
    "    if not os.path.exists(PBF_inputfile) or update is True:\n",
    "        print(f\"{geofabrik_filename} does not exist, downloading to {PBF_inputfile}\")\n",
    "        #  create data/osm directory\n",
    "        os.makedirs(os.path.dirname(PBF_inputfile), exist_ok=True)\n",
    "        with requests.get(geofabrik_url, stream=True) as r:\n",
    "            with open(PBF_inputfile, \"wb\") as f:\n",
    "                shutil.copyfileobj(r.raw, f)\n",
    "\n",
    "    return PBF_inputfile\n",
    "\n",
    "\n",
    "def download_and_filter(country_code, update=False):\n",
    "    PBF_inputfile = download_pbf(country_code, update)\n",
    "\n",
    "    filter_file_exists = False\n",
    "    # json file for the Data dictionary\n",
    "    JSON_outputfile = os.path.join(\n",
    "        os.getcwd(), \"data\", \"osm\", country_code + \"_power.json\"\n",
    "    )  # json file for the Elements dictionary is automatically written to \"data/osm/Elements\"+filename)\n",
    "\n",
    "    if os.path.exists(JSON_outputfile):\n",
    "        filter_file_exists = True\n",
    "\n",
    "    # Load Previously Pre-Filtered Files\n",
    "    if update is False and filter_file_exists is True:\n",
    "        create_elements = False  # Do not create elements again\n",
    "        new_prefilter_data = False  # Do not pre-filter data again\n",
    "        # HACKY: esy.osmfilter code to re-create Data.pickle\n",
    "        Data = osm_info.ReadJason(JSON_outputfile, verbose=\"no\")\n",
    "        DataDict = {\"Data\": Data}\n",
    "        osm_pickle.picklesave(\n",
    "            DataDict,\n",
    "            os.path.realpath(\n",
    "                os.path.join(os.getcwd(), os.path.dirname(JSON_outputfile))\n",
    "            ),\n",
    "        )\n",
    "        print(f\"Loading Pickle for {AFRICA_CC[country_code]}\")  # TODO: Change to Logger\n",
    "    else:\n",
    "        create_elements = True\n",
    "        new_prefilter_data = True\n",
    "        print(\n",
    "            f\"Creating  New Elements for {AFRICA_CC[country_code]}\"\n",
    "        )  # TODO: Change to Logger\n",
    "\n",
    "    prefilter = {\n",
    "        Node: {\"power\": [\"substation\", \"line\", \"generator\"]},\n",
    "        Way: {\"power\": [\"substation\", \"line\", \"generator\"]},\n",
    "        Relation: {\"power\": [\"substation\", \"line\", \"generator\"]},\n",
    "    }  # see https://dlr-ve-esy.gitlab.io/esy-osmfilter/filter.html for filter structures\n",
    "    # HACKY: due to esy.osmfilter validation\n",
    "\n",
    "    blackfilter = [\n",
    "        (\"\", \"\"),\n",
    "    ]\n",
    "\n",
    "    for feature in [\"substation\", \"line\", \"generator\"]:\n",
    "        whitefilter = [\n",
    "            [\n",
    "                (\"power\", feature),\n",
    "            ],\n",
    "        ]\n",
    "        elementname = f\"{country_code}_{feature}s\"\n",
    "\n",
    "        feature_data = run_filter(\n",
    "            elementname,\n",
    "            PBF_inputfile,\n",
    "            JSON_outputfile,\n",
    "            prefilter,\n",
    "            whitefilter,\n",
    "            blackfilter,\n",
    "            NewPreFilterData=new_prefilter_data,\n",
    "            CreateElements=create_elements,\n",
    "            LoadElements=True,\n",
    "            verbose=False,\n",
    "            multiprocess=True,\n",
    "        )\n",
    "\n",
    "        if feature == \"substation\":\n",
    "            substation_data = feature_data\n",
    "        if feature == \"line\":\n",
    "            line_data = feature_data\n",
    "        if feature == \"generator\":\n",
    "            generator_data = feature_data\n",
    "\n",
    "    return (substation_data, line_data, generator_data)\n",
    "\n",
    "\n",
    "# Convert Ways to Point Coordinates\n",
    "\n",
    "\n",
    "# TODO: Use shapely and merge with convert_ways_lines\n",
    "def convert_ways_nodes(df_way, Data):\n",
    "    lonlat_column = []\n",
    "    col = \"refs\"\n",
    "    df_way[col] = (\n",
    "        pd.Series().astype(float) if col not in df_way.columns else df_way[col]\n",
    "    )  # create empty \"refs\" if not in dataframe\n",
    "    for ref in df_way[\"refs\"]:\n",
    "        lonlats = []\n",
    "        for r in ref:\n",
    "            lonlat = Data[\"Node\"][str(r)][\"lonlat\"]\n",
    "            lonlats.append(lonlat)\n",
    "        lonlats = np.array(lonlats)\n",
    "        lonlat = np.mean(lonlats, axis=0)  # Hacky Apporx Centroid\n",
    "        lonlat_column.append(lonlat)\n",
    "    df_way.drop(\"refs\", axis=1, inplace=True, errors=\"ignore\")\n",
    "    df_way.insert(0, \"lonlat\", lonlat_column)\n",
    "\n",
    "\n",
    "# Convert Ways to Line Coordinates\n",
    "\n",
    "\n",
    "def convert_ways_lines(df_way, Data):\n",
    "    lonlat_column = []\n",
    "    for ref in df_way[\"refs\"]:  # goes through each row in df_way[\"refs\"]\n",
    "        lonlats = []\n",
    "        # picks each element in ref & replaces ID by coordinate tuple (A multiline consist of several points)\n",
    "        for r in ref:\n",
    "            # \"r\" is the ID in Data[\"Node\"], [\"lonlat\"] a list of [x1,y1] (coordinates)\n",
    "            lonlat = Data[\"Node\"][str(r)][\"lonlat\"]\n",
    "            lonlat = tuple(lonlat)\n",
    "            lonlats.append(lonlat)  # a list with tuples\n",
    "        lonlat_column.append(lonlats)  # adding a new list of tuples every row\n",
    "    df_way.drop(\"refs\", axis=1, inplace=True)\n",
    "    df_way.insert(1, \"lonlat\", lonlat_column)\n",
    "\n",
    "\n",
    "# Convert Points Pandas Dataframe to GeoPandas Dataframe\n",
    "\n",
    "\n",
    "def convert_pd_to_gdf(df_way):\n",
    "    gdf = gpd.GeoDataFrame(df_way, geometry=[Point(x, y) for x, y in df_way.lonlat], crs=\"EPSG:4326\")\n",
    "    gdf.drop(columns=[\"lonlat\"], inplace=True)\n",
    "    return gdf\n",
    "\n",
    "\n",
    "# Convert Lines Pandas Dataframe to GeoPandas Dataframe\n",
    "\n",
    "\n",
    "def convert_pd_to_gdf_lines(df_way, simplified=False):\n",
    "    df_way[\"geometry\"] = df_way[\"lonlat\"].apply(lambda x: LineString(x))\n",
    "    if simplified is True:\n",
    "        df_way[\"geometry\"] = df_way[\"geometry\"].apply(\n",
    "            lambda x: x.simplify(0.005, preserve_topology=False)\n",
    "        )\n",
    "    gdf = gpd.GeoDataFrame(df_way, geometry=\"geometry\", crs=\"EPSG:4326\")\n",
    "    gdf.drop(columns=[\"lonlat\"], inplace=True)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "\n",
    "# Convert Filtered Data, Elements to Pandas Dataframes\n",
    "\n",
    "\n",
    "def convert_filtered_data_to_dfs(country_code, feature_data, feature):\n",
    "    [Data, Elements] = feature_data\n",
    "    elementname = f\"{country_code}_{feature}s\"\n",
    "    df_way = pd.json_normalize(Elements[elementname][\"Way\"].values())\n",
    "    df_node = pd.json_normalize(Elements[elementname][\"Node\"].values())\n",
    "    return (df_node, df_way, Data)\n",
    "\n",
    "\n",
    "def process_substation_data(country_code, substation_data):\n",
    "    df_node, df_way, Data = convert_filtered_data_to_dfs(\n",
    "        country_code, substation_data, \"substation\"\n",
    "    )\n",
    "    convert_ways_nodes(df_way, Data)\n",
    "    # Add Type Column\n",
    "    df_node[\"Type\"] = \"Node\"\n",
    "    df_way[\"Type\"] = \"Way\"\n",
    "\n",
    "    df_combined = pd.concat([df_node, df_way], axis=0)\n",
    "    # Add Country Column\n",
    "    df_combined[\"Country\"] = AFRICA_CC[country_code]\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "\n",
    "def process_line_data(country_code, line_data):\n",
    "    df_node, df_way, Data = convert_filtered_data_to_dfs(\n",
    "        country_code, line_data, \"line\"\n",
    "    )\n",
    "    convert_ways_lines(df_way, Data)\n",
    "    # Add Type Column\n",
    "    df_way[\"Type\"] = \"Way\"\n",
    "\n",
    "    # Add Country Column\n",
    "    df_way[\"Country\"] = AFRICA_CC[country_code]\n",
    "    return df_way\n",
    "\n",
    "\n",
    "def process_generator_data(country_code, generator_data):\n",
    "    df_node, df_way, Data = convert_filtered_data_to_dfs(\n",
    "        country_code, generator_data, \"generator\"\n",
    "    )\n",
    "    convert_ways_nodes(df_way, Data)\n",
    "    # Add Type Column\n",
    "    df_node[\"Type\"] = \"Node\"\n",
    "    df_way[\"Type\"] = \"Way\"\n",
    "\n",
    "    df_combined = pd.concat([df_node, df_way], axis=0)\n",
    "    # Add Country Column\n",
    "    df_combined[\"Country\"] = AFRICA_CC[country_code]\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "\n",
    "def process_data():\n",
    "    df_all_substations = pd.DataFrame()\n",
    "    df_all_lines = pd.DataFrame()\n",
    "    df_all_generators = pd.DataFrame()\n",
    "    # test_CC = {\"NG\": \"nigeria\"}\n",
    "    for country_code in AFRICA_CC.keys():\n",
    "        substation_data, line_data, generator_data = download_and_filter(country_code)\n",
    "        for feature in [\"substation\", \"line\", \"generator\"]:\n",
    "            if feature == \"substation\":\n",
    "                df_substation = process_substation_data(country_code, substation_data)\n",
    "                df_all_substations = pd.concat([df_all_substations, df_substation])\n",
    "            if feature == \"line\":\n",
    "                df_line = process_line_data(country_code, line_data)\n",
    "                df_all_lines = pd.concat([df_all_lines, df_line])\n",
    "            if feature == \"generator\":\n",
    "                df_generator = process_generator_data(country_code, generator_data)\n",
    "                df_all_generators = pd.concat([df_all_generators, df_generator])\n",
    "\n",
    "    # ----------- SUBSTATIONS -----------\n",
    "\n",
    "    # Columns of interest\n",
    "    df_all_substations = df_all_substations[\n",
    "        df_all_substations &\n",
    "        [\n",
    "            \"id\",\n",
    "            \"lonlat\",\n",
    "            \"tags.power\",\n",
    "            \"tags.substation\",\n",
    "            \"tags.voltage\",\n",
    "            \"tags.frequency\",\n",
    "            \"Type\",\n",
    "            \"Country\",\n",
    "        ]\n",
    "    ]\n",
    "    df_all_substations.drop(df_all_substations.loc[df_all_substations['tags.substation']=='industrial'].index, inplace=True) # Drop industrial substations\n",
    "    df_all_substations.drop(df_all_substations.loc[df_all_substations['tags.substation']=='distribution'].index, inplace=True) # Drop distribution substations\n",
    "\n",
    "    # Generate Files\n",
    "    outputfile_partial = os.path.join(\n",
    "        os.getcwd(), \"data\", \"africa_all\" + \"_substations.\"\n",
    "    )\n",
    "    df_all_substations.to_csv(outputfile_partial + \"csv\")  # Generate CSV\n",
    "    gdf_substations = convert_pd_to_gdf(df_all_substations)\n",
    "    gdf_substations.to_file(\n",
    "        outputfile_partial + \"geojson\", driver=\"GeoJSON\"\n",
    "    )  # Generate GeoJson\n",
    "\n",
    "    # ----------- LINES -----------\n",
    "\n",
    "    # Columns of interest\n",
    "    df_all_lines = df_all_lines[\n",
    "        {\n",
    "            \"id\",\n",
    "            \"lonlat\",\n",
    "            \"tags.power\",\n",
    "            \"tags.cables\",\n",
    "            \"tags.voltage\",\n",
    "            \"tags.circuits\",\n",
    "            \"tags.frequency\",\n",
    "            \"Type\",\n",
    "            \"Country\",\n",
    "        }\n",
    "    ]\n",
    "    # Generate Files\n",
    "    outputfile_partial = os.path.join(os.getcwd(), \"data\", \"africa_all\" + \"_lines.\")\n",
    "    df_all_lines.to_csv(outputfile_partial + \"csv\")  # Generate CSV\n",
    "    gdf_lines = convert_pd_to_gdf_lines(df_all_lines, simplified=True)\n",
    "    gdf_lines.to_file(\n",
    "        outputfile_partial + \"geojson\", driver=\"GeoJSON\"\n",
    "    )  # Generate GeoJson\n",
    "\n",
    "    # ----------- Generator -----------\n",
    "\n",
    "    # Columns of interest\n",
    "    df_all_generators = df_all_generators[\n",
    "        {\n",
    "            \"id\",\n",
    "            \"lonlat\",\n",
    "            \"tags.power\",\n",
    "            \"tags.generator:type\",\n",
    "            \"tags.generator:method\",\n",
    "            \"tags.generator:source\",\n",
    "            \"tags.generator:output:electricity\",\n",
    "            \"Type\",\n",
    "            \"Country\",\n",
    "        }\n",
    "    ]\n",
    "    # Generate Files\n",
    "    outputfile_partial = os.path.join(\n",
    "        os.getcwd(), \"data\", \"africa_all\" + \"_generators.\"\n",
    "    )\n",
    "    df_all_generators.to_csv(outputfile_partial + \"csv\")  # Generate CSV\n",
    "    gdf_generators = convert_pd_to_gdf(df_all_generators)\n",
    "    gdf_generators.to_file(\n",
    "        outputfile_partial + \"geojson\", driver=\"GeoJSON\"\n",
    "    )  # Generate GeoJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overwrite Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_ways_lines(df_way, Data):\n",
    "    lonlat_column = []\n",
    "    \n",
    "    for ref in df_way[\"refs\"]:  # goes through each row in df_way['refs']\n",
    "        lonlats = []\n",
    "        # picks each element in ref & replaces ID by coordinate tuple (A multiline consist of several points)\n",
    "        for r in ref:\n",
    "            # \"r\" is the ID in Data[\"Node\"], [\"lonlat\"] a list of [x1,y1] (coordinates)\n",
    "            lonlat = Data[\"Node\"][str(r)][\"lonlat\"]\n",
    "            # try:\n",
    "            #     print(Data[\"Node\"][str(r)[]])\n",
    "            lonlat = tuple(lonlat)\n",
    "            lonlats.append(lonlat)  # a list with tuples\n",
    "        lonlat_column.append(lonlats)  # adding a new list of tuples every row\n",
    "    # df_way.drop('refs', axis=1, inplace=True)\n",
    "    df_way.insert(1, \"lonlat\", lonlat_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line_data(country_code, line_data):\n",
    "    df_node, df_way, Data = convert_filtered_data_to_dfs(country_code, line_data, 'line')\n",
    "    convert_ways_lines(df_way, Data)\n",
    "    # Add Type Column\n",
    "    df_way['Type'] = 'Way'\n",
    "\n",
    "    # Add Country Column\n",
    "    df_way['Country'] = AFRICA_CC[country_code]\n",
    "    return df_way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pickle for nigeria\n"
     ]
    }
   ],
   "source": [
    "df_all_substations = pd.DataFrame()\n",
    "df_all_lines = pd.DataFrame()\n",
    "df_all_generators = pd.DataFrame()\n",
    "test_CC = {\"NG\": \"nigeria\"}\n",
    "for country_code in test_CC.keys():\n",
    "    substation_data, line_data, generator_data = download_and_filter(country_code)\n",
    "    for feature in [\"substation\", \"line\",\"generator\"]:\n",
    "        if feature == 'substation':\n",
    "            df_substation = process_substation_data(country_code, substation_data)\n",
    "            df_all_substations = pd.concat(\n",
    "                [df_all_substations, df_substation])\n",
    "        if feature == 'line':\n",
    "            df_line = process_line_data(country_code, line_data)\n",
    "            df_all_lines = pd.concat([df_all_lines, df_line])\n",
    "        if feature == 'generator':\n",
    "            df_generator = process_generator_data(country_code, generator_data)\n",
    "            df_all_generators = pd.concat(\n",
    "                [df_all_generators, df_generator])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Substations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>lonlat</th>\n      <th>tags.power</th>\n      <th>tags.operator</th>\n      <th>tags.name</th>\n      <th>tags.substation</th>\n      <th>tags.ref</th>\n      <th>Type</th>\n      <th>tags.voltage</th>\n      <th>tags.location</th>\n      <th>...</th>\n      <th>tags.fixme</th>\n      <th>tags.landuse</th>\n      <th>tags.source</th>\n      <th>tags.website</th>\n      <th>tags.building</th>\n      <th>tags.addr:city</th>\n      <th>tags.addr:street</th>\n      <th>tags.area</th>\n      <th>tags.access</th>\n      <th>Country</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2000011529</td>\n      <td>[5.580595199999979, 6.357239900000047]</td>\n      <td>substation</td>\n      <td>Transformer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Node</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2161137620</td>\n      <td>[5.612709500000012, 6.298418899999993]</td>\n      <td>substation</td>\n      <td>Transformer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Node</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2161121796</td>\n      <td>[5.605644800000013, 6.292686199999994]</td>\n      <td>substation</td>\n      <td>Transformer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Node</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5604720218</td>\n      <td>[13.140950299999984, 11.811399999999967]</td>\n      <td>substation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Node</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3605463946</td>\n      <td>[7.054147699999979, 4.792176100000002]</td>\n      <td>substation</td>\n      <td>PHED</td>\n      <td>Okuru Injection Substation</td>\n      <td>distribution</td>\n      <td>NaN</td>\n      <td>Node</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>163</th>\n      <td>553840946</td>\n      <td>[7.407928399999965, 6.430845528571455]</td>\n      <td>substation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Way</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>164</th>\n      <td>745794408</td>\n      <td>[3.5061223199999914, 6.625164779999999]</td>\n      <td>substation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Way</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>108020974</td>\n      <td>[3.2482386500000224, 6.60293714]</td>\n      <td>substation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>transmission</td>\n      <td>NaN</td>\n      <td>Way</td>\n      <td>330000</td>\n      <td>outdoor</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>166</th>\n      <td>564766375</td>\n      <td>[6.32832122857142, 4.990267728571405]</td>\n      <td>substation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Way</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nigeria</td>\n    </tr>\n    <tr>\n      <th>167</th>\n      <td>567184002</td>\n      <td>[5.791706220000021, 5.560308719999972]</td>\n      <td>substation</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>transmission</td>\n      <td>NaN</td>\n      <td>Way</td>\n      <td>132000</td>\n      <td>outdoor</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>nigeria</td>\n    </tr>\n  </tbody>\n</table>\n<p>182 rows × 21 columns</p>\n</div>",
      "text/plain": "             id                                    lonlat  tags.power  \\\n0    2000011529    [5.580595199999979, 6.357239900000047]  substation   \n1    2161137620    [5.612709500000012, 6.298418899999993]  substation   \n2    2161121796    [5.605644800000013, 6.292686199999994]  substation   \n3    5604720218  [13.140950299999984, 11.811399999999967]  substation   \n4    3605463946    [7.054147699999979, 4.792176100000002]  substation   \n..          ...                                       ...         ...   \n163   553840946    [7.407928399999965, 6.430845528571455]  substation   \n164   745794408   [3.5061223199999914, 6.625164779999999]  substation   \n165   108020974          [3.2482386500000224, 6.60293714]  substation   \n166   564766375     [6.32832122857142, 4.990267728571405]  substation   \n167   567184002    [5.791706220000021, 5.560308719999972]  substation   \n\n    tags.operator                   tags.name tags.substation tags.ref  Type  \\\n0     Transformer                         NaN             NaN      NaN  Node   \n1     Transformer                         NaN             NaN      NaN  Node   \n2     Transformer                         NaN             NaN      NaN  Node   \n3             NaN                         NaN             NaN      NaN  Node   \n4            PHED  Okuru Injection Substation    distribution      NaN  Node   \n..            ...                         ...             ...      ...   ...   \n163           NaN                         NaN             NaN      NaN   Way   \n164           NaN                         NaN             NaN      NaN   Way   \n165           NaN                         NaN    transmission      NaN   Way   \n166           NaN                         NaN             NaN      NaN   Way   \n167           NaN                         NaN    transmission      NaN   Way   \n\n    tags.voltage tags.location  ... tags.fixme tags.landuse tags.source  \\\n0            NaN           NaN  ...        NaN          NaN         NaN   \n1            NaN           NaN  ...        NaN          NaN         NaN   \n2            NaN           NaN  ...        NaN          NaN         NaN   \n3            NaN           NaN  ...        NaN          NaN         NaN   \n4            NaN           NaN  ...        NaN          NaN         NaN   \n..           ...           ...  ...        ...          ...         ...   \n163          NaN           NaN  ...        NaN          NaN         NaN   \n164          NaN           NaN  ...        NaN          NaN         NaN   \n165       330000       outdoor  ...        NaN          NaN         NaN   \n166          NaN           NaN  ...        NaN          NaN         NaN   \n167       132000       outdoor  ...        NaN          NaN         NaN   \n\n    tags.website tags.building tags.addr:city tags.addr:street tags.area  \\\n0            NaN           NaN            NaN              NaN       NaN   \n1            NaN           NaN            NaN              NaN       NaN   \n2            NaN           NaN            NaN              NaN       NaN   \n3            NaN           NaN            NaN              NaN       NaN   \n4            NaN           NaN            NaN              NaN       NaN   \n..           ...           ...            ...              ...       ...   \n163          NaN           NaN            NaN              NaN       NaN   \n164          NaN           NaN            NaN              NaN       NaN   \n165          NaN           NaN            NaN              NaN       NaN   \n166          NaN           NaN            NaN              NaN       NaN   \n167          NaN           NaN            NaN              NaN       NaN   \n\n    tags.access  Country  \n0           NaN  nigeria  \n1           NaN  nigeria  \n2           NaN  nigeria  \n3           NaN  nigeria  \n4           NaN  nigeria  \n..          ...      ...  \n163         NaN  nigeria  \n164         NaN  nigeria  \n165         NaN  nigeria  \n166         NaN  nigeria  \n167         NaN  nigeria  \n\n[182 rows x 21 columns]"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_substations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['refs'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4782a44feb73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moutputfile_partial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'africa_all'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_substations.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf_all_substations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputfile_partial\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Generate CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgdf_substations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_pd_to_gdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_all_substations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'refs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mgdf_substations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputfile_partial\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'geojson'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"GeoJSON\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Generate GeoJson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pypsa/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4313\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4314\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4315\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4316\u001b[0m         )\n\u001b[1;32m   4317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pypsa/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4151\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4152\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4153\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pypsa/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   4186\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4187\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4188\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4189\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pypsa/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5589\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5590\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5591\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5592\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5593\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['refs'] not found in axis\""
     ]
    }
   ],
   "source": [
    "#----------- SUBSTATIONS -----------\n",
    "\n",
    "# Clean\n",
    "df_all_substations.reset_index(drop=True, inplace=True)\n",
    "df_all_substations.dropna(thresh=len(df_all_substations)*0.25, axis=1, how='all', inplace = True) #Drop Columns with 75% values as N/A\n",
    "# df_all_substations.dropna(subset=['tags.voltage'], inplace = True) # Drop any substations with Voltage = N/A\n",
    "# df_all_substations.drop(df_all_substations.loc[df_all_substations['tags.substation']=='industrial'].index, inplace=True)\n",
    "# df_all_substations.drop(df_all_substations.loc[df_all_substations['tags.substation']=='distribution'].index, inplace=True)\n",
    "\n",
    "# Generate Files\n",
    "outputfile_partial = os.path.join(os.getcwd(),'data','africa_all'+'_substations.')\n",
    "df_all_substations.to_csv(outputfile_partial + 'csv') # Generate CSV\n",
    "gdf_substations = convert_pd_to_gdf(df_all_substations.drop('refs', 1))\n",
    "gdf_substations.to_file(outputfile_partial+'geojson', driver=\"GeoJSON\")  # Generate GeoJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Generator -----------\n",
    "\n",
    "df_all_generators.reset_index(drop=True, inplace=True)\n",
    "df_all_generators.drop(columns = [\"tags.fixme\",\"tags.frequency\",\"tags.name:ar\",\"tags.building\",\"tags.barrier\"], inplace = True, errors='ignore')\n",
    "df_all_generators = df_all_generators[df_all_generators['tags.generator:output:electricity'].astype(str).str.contains('MW')] #removes boolean \n",
    "df_all_generators['tags.generator:output:electricity'] = df_all_generators['tags.generator:output:electricity'].str.extract('(\\d+)').astype(float)\n",
    "df_all_generators.rename(columns = {'tags.generator:output:electricity':\"power_output_MW\"}, inplace = True)\n",
    "df_all_generators.dropna(thresh=len(df_all_generators)*0.25, axis=1, how='all', inplace=True) # Drop Columns with 75% values as N/A\n",
    "\n",
    "# Generate Files\n",
    "outputfile_partial = os.path.join(os.getcwd(),'data','africa_all'+'_generators.')\n",
    "df_all_generators.to_csv(outputfile_partial + 'csv') # Generate CSV\n",
    "gdf_generators = convert_pd_to_gdf(df_all_generators)\n",
    "gdf_generators.to_file(outputfile_partial+'geojson', driver=\"GeoJSON\")  # Generate GeoJson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- LINES -----------\n",
    "\n",
    "# Clean\n",
    "# TODO: FIX Voltage Filter\n",
    "# Some transmission lines carry multiple voltages, having voltage_V = 10000;20000  (two lines)\n",
    "# The following code keeps only the first information before the semicolon..\n",
    "# Needs to be corrected in future, creating two lines with the same bus ID.\n",
    "\n",
    "\n",
    "df_all_lines = df_all_lines[\n",
    "        {\n",
    "            \"id\",\n",
    "            \"refs\",\n",
    "            \"lonlat\",\n",
    "            \"tags.power\",\n",
    "            \"tags.cables\",\n",
    "            \"tags.voltage\",\n",
    "            \"tags.frequency\",\n",
    "            \"Type\",\n",
    "            \"Country\",\n",
    "        }\n",
    "    ]\n",
    "\n",
    "# Clean data    \n",
    "df_all_lines = df_all_lines.reset_index(drop=True)\n",
    "df_all_lines = df_all_lines.dropna(subset=['tags.voltage']) # Drop any lines with Voltage = N/A\n",
    "df_all_lines = df_all_lines.rename(columns = {'tags.voltage':\"voltage_V\"}) \n",
    "df_all_lines['voltage_V'] = df_all_lines['voltage_V'].str.split('*').str[0] #just keeps the \n",
    "df_all_lines['voltage_V'] = df_all_lines['voltage_V'].str.split(';').str[0]\n",
    "df_all_lines['voltage_V'] = df_all_lines['voltage_V'].apply(lambda x: pd.to_numeric(x, errors='coerce')).dropna() ## if cell can't converted to float -> drop\n",
    "df_all_lines = df_all_lines[df_all_lines.voltage_V > 10000]\n",
    "# df_all_lines['end_refs'] = \n",
    "\n",
    "# Generate Files\n",
    "outputfile_partial = os.path.join(os.getcwd(), 'data', 'africa_all'+'_lines.')  \n",
    "df_all_lines.to_csv(outputfile_partial + 'csv')  # Generate CSV\n",
    "gdf_lines = convert_pd_to_gdf_lines(df_all_lines.drop('refs', 1), simplified=True)\n",
    "gdf_lines.to_file(outputfile_partial+'geojson',\n",
    "            driver=\"GeoJSON\")  # Generate GeoJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['refs'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2df52ab76205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_line_lookup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_all_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'refs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_line_lookup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pypsa/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3028\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3030\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3032\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pypsa/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pypsa/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['refs'] not in index\""
     ]
    }
   ],
   "source": [
    "df_line_lookup = df_all_lines[['id','refs']]\n",
    "display(df_line_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>refs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>564755236</td>\n      <td>[5440518752, 5440518751, 5440518750, 544051874...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>567535340</td>\n      <td>[5462602236, 5462602234, 5462602233, 546260223...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>592191538</td>\n      <td>[5652509019, 5652509020, 5652509121, 565250912...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>564458980</td>\n      <td>[5438478937, 5438478936, 5438478935, 543847893...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>655273140</td>\n      <td>[6139631838, 6139631837, 6139631836, 613963183...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>177</th>\n      <td>553840946</td>\n      <td>[5345637324, 5345637323, 5345637322, 534563622...</td>\n    </tr>\n    <tr>\n      <th>178</th>\n      <td>745794408</td>\n      <td>[6980276932, 6980276933, 6980276934, 698027693...</td>\n    </tr>\n    <tr>\n      <th>179</th>\n      <td>108020974</td>\n      <td>[1240204635, 1240204684, 1240204688, 306400478...</td>\n    </tr>\n    <tr>\n      <th>180</th>\n      <td>564766375</td>\n      <td>[5440610911, 5440610910, 5440610909, 544061090...</td>\n    </tr>\n    <tr>\n      <th>181</th>\n      <td>567184002</td>\n      <td>[5460459805, 5460459804, 5460459803, 546045980...</td>\n    </tr>\n  </tbody>\n</table>\n<p>168 rows × 2 columns</p>\n</div>",
      "text/plain": "            id                                               refs\n14   564755236  [5440518752, 5440518751, 5440518750, 544051874...\n15   567535340  [5462602236, 5462602234, 5462602233, 546260223...\n16   592191538  [5652509019, 5652509020, 5652509121, 565250912...\n17   564458980  [5438478937, 5438478936, 5438478935, 543847893...\n18   655273140  [6139631838, 6139631837, 6139631836, 613963183...\n..         ...                                                ...\n177  553840946  [5345637324, 5345637323, 5345637322, 534563622...\n178  745794408  [6980276932, 6980276933, 6980276934, 698027693...\n179  108020974  [1240204635, 1240204684, 1240204688, 306400478...\n180  564766375  [5440610911, 5440610910, 5440610909, 544061090...\n181  567184002  [5460459805, 5460459804, 5460459803, 546045980...\n\n[168 rows x 2 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_node_lookup = df_all_substations[['id','refs']]\n",
    "df_node_lookup = df_node_lookup.dropna(subset=['refs']) # Drop any nodes with refs = N/A\n",
    "display(df_node_lookup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_df(df):\n",
    "    out = []\n",
    "    for n, row in df.iterrows():\n",
    "        for item in row['refs']:\n",
    "            row['flat_ref'] = item\n",
    "            out += [row.copy()]\n",
    "\n",
    "    flattened_df = pd.DataFrame(out)\n",
    "    flattened_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return flattened_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>refs</th>\n      <th>flat_ref</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>556530547</td>\n      <td>[2725719269, 2725912800, 2725719240, 272571923...</td>\n      <td>2725719269</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>556530547</td>\n      <td>[2725719269, 2725912800, 2725719240, 272571923...</td>\n      <td>2725912800</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>556530547</td>\n      <td>[2725719269, 2725912800, 2725719240, 272571923...</td>\n      <td>2725719240</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>556530547</td>\n      <td>[2725719269, 2725912800, 2725719240, 272571923...</td>\n      <td>2725719238</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>556530547</td>\n      <td>[2725719269, 2725912800, 2725719240, 272571923...</td>\n      <td>5368625277</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>32133</th>\n      <td>695800745</td>\n      <td>[6533692645, 6533692646, 6533692647, 653369264...</td>\n      <td>6533703128</td>\n    </tr>\n    <tr>\n      <th>32134</th>\n      <td>695800745</td>\n      <td>[6533692645, 6533692646, 6533692647, 653369264...</td>\n      <td>6533703129</td>\n    </tr>\n    <tr>\n      <th>32135</th>\n      <td>695800745</td>\n      <td>[6533692645, 6533692646, 6533692647, 653369264...</td>\n      <td>6533703130</td>\n    </tr>\n    <tr>\n      <th>32136</th>\n      <td>695800745</td>\n      <td>[6533692645, 6533692646, 6533692647, 653369264...</td>\n      <td>6533703131</td>\n    </tr>\n    <tr>\n      <th>32137</th>\n      <td>695800745</td>\n      <td>[6533692645, 6533692646, 6533692647, 653369264...</td>\n      <td>6533703153</td>\n    </tr>\n  </tbody>\n</table>\n<p>32138 rows × 3 columns</p>\n</div>",
      "text/plain": "              id                                               refs  \\\n0      556530547  [2725719269, 2725912800, 2725719240, 272571923...   \n1      556530547  [2725719269, 2725912800, 2725719240, 272571923...   \n2      556530547  [2725719269, 2725912800, 2725719240, 272571923...   \n3      556530547  [2725719269, 2725912800, 2725719240, 272571923...   \n4      556530547  [2725719269, 2725912800, 2725719240, 272571923...   \n...          ...                                                ...   \n32133  695800745  [6533692645, 6533692646, 6533692647, 653369264...   \n32134  695800745  [6533692645, 6533692646, 6533692647, 653369264...   \n32135  695800745  [6533692645, 6533692646, 6533692647, 653369264...   \n32136  695800745  [6533692645, 6533692646, 6533692647, 653369264...   \n32137  695800745  [6533692645, 6533692646, 6533692647, 653369264...   \n\n         flat_ref  \n0      2725719269  \n1      2725912800  \n2      2725719240  \n3      2725719238  \n4      5368625277  \n...           ...  \n32133  6533703128  \n32134  6533703129  \n32135  6533703130  \n32136  6533703131  \n32137  6533703153  \n\n[32138 rows x 3 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "way_f = flatten_df(df_line_lookup)\n",
    "display(way_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>refs</th>\n      <th>flat_ref</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>564755236</td>\n      <td>[5440518752, 5440518751, 5440518750, 544051874...</td>\n      <td>5440518752</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>564755236</td>\n      <td>[5440518752, 5440518751, 5440518750, 544051874...</td>\n      <td>5440518751</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>564755236</td>\n      <td>[5440518752, 5440518751, 5440518750, 544051874...</td>\n      <td>5440518750</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>564755236</td>\n      <td>[5440518752, 5440518751, 5440518750, 544051874...</td>\n      <td>5440518747</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>564755236</td>\n      <td>[5440518752, 5440518751, 5440518750, 544051874...</td>\n      <td>5440518748</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1231</th>\n      <td>567184002</td>\n      <td>[5460459805, 5460459804, 5460459803, 546045980...</td>\n      <td>5460459805</td>\n    </tr>\n    <tr>\n      <th>1232</th>\n      <td>567184002</td>\n      <td>[5460459805, 5460459804, 5460459803, 546045980...</td>\n      <td>5460459804</td>\n    </tr>\n    <tr>\n      <th>1233</th>\n      <td>567184002</td>\n      <td>[5460459805, 5460459804, 5460459803, 546045980...</td>\n      <td>5460459803</td>\n    </tr>\n    <tr>\n      <th>1234</th>\n      <td>567184002</td>\n      <td>[5460459805, 5460459804, 5460459803, 546045980...</td>\n      <td>5460459802</td>\n    </tr>\n    <tr>\n      <th>1235</th>\n      <td>567184002</td>\n      <td>[5460459805, 5460459804, 5460459803, 546045980...</td>\n      <td>5460459805</td>\n    </tr>\n  </tbody>\n</table>\n<p>1236 rows × 3 columns</p>\n</div>",
      "text/plain": "             id                                               refs    flat_ref\n0     564755236  [5440518752, 5440518751, 5440518750, 544051874...  5440518752\n1     564755236  [5440518752, 5440518751, 5440518750, 544051874...  5440518751\n2     564755236  [5440518752, 5440518751, 5440518750, 544051874...  5440518750\n3     564755236  [5440518752, 5440518751, 5440518750, 544051874...  5440518747\n4     564755236  [5440518752, 5440518751, 5440518750, 544051874...  5440518748\n...         ...                                                ...         ...\n1231  567184002  [5460459805, 5460459804, 5460459803, 546045980...  5460459805\n1232  567184002  [5460459805, 5460459804, 5460459803, 546045980...  5460459804\n1233  567184002  [5460459805, 5460459804, 5460459803, 546045980...  5460459803\n1234  567184002  [5460459805, 5460459804, 5460459803, 546045980...  5460459802\n1235  567184002  [5460459805, 5460459804, 5460459803, 546045980...  5460459805\n\n[1236 rows x 3 columns]"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_f = flatten_df(df_node_lookup)\n",
    "display(node_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id_x</th>\n      <th>refs_x</th>\n      <th>flat_ref</th>\n      <th>id_y</th>\n      <th>refs_y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>553772749</td>\n      <td>[5345033041, 5432224011, 5345036235, 534503304...</td>\n      <td>5345033046</td>\n      <td>553772750</td>\n      <td>[5345033057, 5345033048, 5345033049, 534503305...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "        id_x                                             refs_x    flat_ref  \\\n0  553772749  [5345033041, 5432224011, 5345036235, 534503304...  5345033046   \n\n        id_y                                             refs_y  \n0  553772750  [5345033057, 5345033048, 5345033049, 534503305...  "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3 = way_f.merge(node_f, on='flat_ref', how='inner')\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_line_refs = set()\n",
    "for ref in df_all_lines[\"refs\"]:  # goes through each row in df_way['refs']\n",
    "    for r in ref:\n",
    "        all_line_refs.add(r)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_st_refs = set()\n",
    "for ref in df_all_substations.dropna(subset=['refs'])[\"refs\"]:  # goes through each row in df_way['refs']\n",
    "    for r in ref:\n",
    "        all_st_refs.add(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_line_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{5345033046}"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_line_refs.intersection(all_st_refs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('pypsa': conda)",
   "name": "python3710jvsc74a57bd09a6789bfb301b77bab315636af11818455845432a243e82ed991667bc6cd3910"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}