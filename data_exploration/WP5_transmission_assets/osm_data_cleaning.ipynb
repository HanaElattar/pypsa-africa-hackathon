{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD NOTEBOOK: SEE osm_pbf_power_data_extractor.py which does everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time\n",
    "#IMPORTANT: RUN SCRIPT FROM THIS SCRIPTS DIRECTORY i.e data_exploration/ TODO: make more robust\n",
    "##os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "sys.path.append('../../scripts')\n",
    "from iso_country_codes import AFRICA_CC\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import geoplot\n",
    "import matplotlib.pyplot as plt\n",
    "from iso_country_codes import AFRICA_CC\n",
    "from osm_pbf_power_data_extractor import convert_pd_to_gdf_lines, convert_pd_to_gdf\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBSTATIONS (Just simple cleaning to test snapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check old buses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pypsa-eur data\n",
    "df_all_buses = (pd.read_csv(os.getcwd()+\"/entsoegridkit/buses.csv\", quotechar=\"'\",\n",
    "                         true_values='t', false_values='f',\n",
    "                         dtype=dict(bus_id=\"str\"))\n",
    "            .set_index(\"bus_id\")\n",
    "            .drop(['station_id'], axis=1)\n",
    "            .rename(columns=dict(voltage='v_nom')))\n",
    "\n",
    "#print(df_all_lines.geometry.unique())\n",
    "#display(df_all_buses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and create final dataframe layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------- SUBSTATIONS -----------\n",
    "# Load uncleaned data\n",
    "df_all_substations = gpd.read_file(os.getcwd()+\"/data/raw/africa_all_raw_substations.geojson\")\n",
    "\n",
    "# Modification - create final dataframe layout\n",
    "df_all_substations = df_all_substations.rename(\n",
    "    columns = {\n",
    "        \"id\": \"bus_id\",\n",
    "        \"tags.voltage\": \"voltage\",\n",
    "        # \"dc\", will be added below\n",
    "        \"tags.power\": \"symbol\",\n",
    "        # \"under_construction\", will be added below     \n",
    "        \"tags.substation\": \"tag_substation\",\n",
    "        \"Country\": \"country\",  # new/different to PyPSA-Eur\n",
    "        \"Area\": \"tag_area\",\n",
    "        \"lonlat\": \"geometry\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add NaN as default\n",
    "df_all_substations[\"station_id\"] = np.nan\n",
    "df_all_substations[\"dc\"] = np.nan\n",
    "df_all_substations[\"under_construction\"] = np.nan\n",
    "df_all_substations[\"lon\"] = df_all_substations[\"geometry\"].x\n",
    "df_all_substations[\"lat\"] = df_all_substations[\"geometry\"].y\n",
    "\n",
    "#Rearrange columns\n",
    "clist = [\"bus_id\",\"station_id\",\"voltage\",\"dc\",\"symbol\",\"under_construction\",\"tag_substation\",\n",
    "         \"tag_area\",\"lon\", \"lat\", \"geometry\",\"country\"]\n",
    "df_all_substations = df_all_substations[clist]\n",
    "\n",
    "# make float to integer\n",
    "df_all_substations[\"bus_id\"] = df_all_substations[\"bus_id\"].astype(int)\n",
    "\n",
    "#display(df_all_substations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define under_construction, dc, filter \"transmission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_substations[\"under_construction\"] = True\n",
    "df_all_substations[\"dc\"] = False\n",
    "df_all_substations = df_all_substations[df_all_substations[\"tag_substation\"] == \"transmission\"] # keep only rows with indexed \"transmission\"\n",
    "#display(df_all_substations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_substations.tags_area.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"] == \"transmission\"].tags_area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"] == \"distribution\"].tags_area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"] == \"industrial\"].tags_area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_substations[df_all_substations[\"tags_substation\"].isna()].tags_area.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all_substations[\"tags_substation\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any row with Voltage = N/A\n",
    "df = df_all_substations.dropna(subset=['voltage']) \n",
    "\n",
    "#Split semicolon separated cells i.e. [66000;220000] and create new identical rows\n",
    "lst_col = 'voltage'\n",
    "x = df.assign(**{lst_col:df[lst_col].str.split(';')})\n",
    "x = pd.DataFrame({\n",
    "    col:np.repeat(x[col].values, x[lst_col].str.len())\n",
    "    for col in x.columns.difference([lst_col])\n",
    "    }).assign(**{lst_col:np.concatenate(x[lst_col].values)})[x.columns.tolist()]\n",
    "df_all_substations = x\n",
    "\n",
    "#display(df_all_substations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique bus id's\n",
    "# The steps below create unique bus id's without loosing the original OSM bus_id \n",
    "\n",
    "# Context\n",
    "# The previous duplication of rows (to split the voltage) lead to a couple of same bus_id\n",
    "\n",
    "# Method\n",
    "# Unique bus_id are created by simply adding -1,-2,-3 to the original bus_id\n",
    "# Every unique id gets a -1 \n",
    "# If a bus_id exist i.e. three times it it will the counted by cumcount -1,-2,-3 making the id unique\n",
    "\n",
    "if df_all_substations[\"bus_id\"].count() != df_all_substations[\"bus_id\"].nunique(): # operate only if line_id is not already unique (nunique counts unique values)\n",
    "    df_all_substations[\"cumcount\"] = df_all_substations.groupby([\"bus_id\"]).cumcount() # create cumcount column. Cumcount counts 0,1,2,3 the number of duplicates\n",
    "    df_all_substations[\"cumcount\"] = df_all_substations[\"cumcount\"] + 1 # avoid 0 value for better understanding\n",
    "    df_all_substations[\"bus_id\"] = df_all_substations[\"bus_id\"].astype(str) + \"-\" + df_all_substations[\"cumcount\"].values.astype(str) # add cumcount to line_id to make line_id unique\n",
    "    df_all_substations.drop(columns = \"cumcount\", inplace=True) # remove cumcount column\n",
    "\n",
    "#display(df_all_substations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all non-numeric values\n",
    "\n",
    "df_all_substations['voltage'] = df_all_substations['voltage'].apply(lambda x: pd.to_numeric(x, errors='coerce')).astype(float) # if cell can't converted to float -> nan\n",
    "df_all_substations = df_all_substations.dropna(subset=['voltage']) # Drop any row with Voltage = N/A\n",
    "df_all_substations.loc[:,\"voltage\"]  = df_all_substations['voltage'].astype(int)\n",
    "#df_all_lines['voltage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows with x > 110 kV as it is considered as transmission level\n",
    "\n",
    "df_all_substations = df_all_substations[df_all_substations.voltage > 110000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_all_substations)\n",
    "# display(df_all_substations['voltage'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Files (CSV+GeoJSON) \n",
    "\n",
    "#### CSV\n",
    "outputfile_partial = os.path.join(os.getcwd(), \"data\", \"clean\", \"africa_all\" + \"_buses\" + \"_clean\") # Output file directory\n",
    "\n",
    "if not os.path.exists(outputfile_partial):\n",
    "    os.makedirs(os.path.dirname(outputfile_partial), exist_ok=True) #  create clean directoryif not already exist\n",
    "    \n",
    "df_all_substations.to_csv(outputfile_partial + \".csv\")  # Generate CSV\n",
    "\n",
    "\n",
    "#### GEOJSON\n",
    "\n",
    "df_all_substations = gpd.GeoDataFrame(df_all_substations, geometry=\"geometry\",crs=\"EPSG:4326\")\n",
    "df_all_substations.to_file(outputfile_partial + \".geojson\", driver=\"GeoJSON\")    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LINES "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check old unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pypsa-eur data\n",
    "df_all_lines = (pd.read_csv(os.getcwd()+\"/entsoegridkit/lines.csv\", quotechar=\"'\", true_values='t', false_values='f',\n",
    "                         dtype=dict(line_id='str', bus0='str', bus1='str',\n",
    "                                    underground=\"bool\", under_construction=\"bool\")).set_index('line_id').rename(columns=dict(voltage='v_nom', circuits='num_parallel')))\n",
    "\n",
    "#print(df_all_lines.geometry.unique())\n",
    "#display(df_all_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data and create final dataframe layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load cables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw cable data\n",
    "df_cables = gpd.read_file(os.getcwd()+\"/data/raw/africa_all_raw_cables.geojson\") \n",
    "\n",
    "# Modification - create final dataframe layout\n",
    "df_cables = df_cables.rename(\n",
    "    columns = {\n",
    "        \"id\": \"line_id\",\n",
    "        \"tags.voltage\": \"voltage\",\n",
    "        \"tags.circuits\": \"circuits\",\n",
    "        \"tags.cables\": \"cables\",\n",
    "        \"tags.frequency\": \"tag_frequency\",\n",
    "        \"tags.power\": \"tag_type\",\n",
    "        \"tags.location\": \"tag_location\",\n",
    "        \"lonlat\": \"geometry\",\n",
    "        \"Country\": \"country\",  # new/different to PyPSA-Eur\n",
    "        \"Length\": \"length\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add NaN as default\n",
    "df_cables[\"bus0\"] = np.nan\n",
    "df_cables[\"bus1\"] = np.nan\n",
    "#df_all_cables[\"length\"] = np.nan # Now in dataset\n",
    "df_cables[\"underground\"] = np.nan\n",
    "df_cables[\"under_construction\"] = np.nan\n",
    "\n",
    "#Rearrange columns\n",
    "clist = [\"line_id\",\"bus0\",\"bus1\",\"voltage\",\"circuits\",\"length\",\"underground\",\n",
    "         \"under_construction\",\"tag_type\",\"tag_frequency\", \"tag_location\",\"geometry\", \"country\"]\n",
    "df_cables = df_cables[clist]\n",
    "\n",
    "# make float to integer\n",
    "df_cables[\"line_id\"] = df_cables[\"line_id\"].astype(int)\n",
    "\n",
    "\n",
    "#display(df_cables)\n",
    "#df_all_cables[df_all_cables['tag_location']== \"overground\"]\n",
    "#df_all_cables[\"tags.location\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw line data\n",
    "df_lines = gpd.read_file(os.getcwd()+\"/data/raw/africa_all_raw_lines.geojson\") \n",
    "\n",
    "# Modification - create final dataframe layout\n",
    "df_lines = df_lines.rename(\n",
    "    columns = {\n",
    "        \"id\": \"line_id\",\n",
    "        \"tags.voltage\": \"voltage\",\n",
    "        \"tags.circuits\": \"circuits\",\n",
    "        \"tags.cables\": \"cables\",\n",
    "        \"tags.frequency\": \"tag_frequency\",\n",
    "        \"tags.power\": \"tag_type\",\n",
    "        \"lonlat\": \"geometry\",\n",
    "        \"Country\": \"country\",  # new/different to PyPSA-Eur\n",
    "        \"Length\": \"length\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add NaN as default\n",
    "df_lines[\"bus0\"] = np.nan\n",
    "df_lines[\"bus1\"] = np.nan\n",
    "#df_all_lines[\"length\"] = np.nan # commented because, we have now length data\n",
    "df_lines[\"underground\"] = np.nan\n",
    "df_lines[\"under_construction\"] = np.nan\n",
    "\n",
    "#Rearrange columns\n",
    "clist = [\"line_id\",\"bus0\",\"bus1\",\"voltage\",\"circuits\",\"length\",\"underground\",\n",
    "         \"under_construction\",\"tag_type\",\"tag_frequency\", \"cables\",\"geometry\", \"country\"]\n",
    "df_lines = df_lines[clist]\n",
    "\n",
    "#display(df_all_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine cable and line to one  \"df_all_lines\" dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_lines = pd.concat([df_lines,df_cables])\n",
    "# df_all_lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define underground, under_construction information, frequency, circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# under construction\n",
    "df_all_lines[\"under_construction\"] = False # default. Not more information atm available\n",
    "\n",
    "# underground\n",
    "df_all_lines[\"underground\"] = (df_all_lines[\"tag_type\"] == \"cable\") # Simplified. If tag_type cable then underground is True. \n",
    "# More information extractable for \"underground\" by looking at \"tag_location\".\n",
    "if 'tag_location' in df_all_lines: # drop column if exist\n",
    "    df_all_lines.drop(columns = \"tag_location\", inplace=True)\n",
    "\n",
    "# frequency\n",
    "df_all_lines[\"tag_frequency\"] = 50\n",
    "#df_all_lines[\"tag_frequency\"].unique()\n",
    "\n",
    "# circuits\n",
    "if df_all_lines[\"cables\"].dtype != int: # if not int make int\n",
    "    df_all_lines.loc[(df_all_lines[\"cables\"] < \"3\") | df_all_lines[\"cables\"].isna(), \"cables\"] = \"0\" #HERE. \"0\" if cables \"None\", \"nan\" or \"1\"\n",
    "    df_all_lines[\"cables\"] = df_all_lines[\"cables\"].astype(\"int\")\n",
    "if 4 or 5 in df_all_lines[\"cables\"].values: # downgrade 4 and 5 cables to 3... \n",
    "    # Reason: 4 cables have 1 lighting protection cables, 5 cables has 2 LP cables - not transferring energy; \n",
    "    # see https://hackaday.com/2019/06/11/a-field-guide-to-transmission-lines/\n",
    "    df_all_lines.loc[(df_all_lines[\"cables\"] == 4) | (df_all_lines[\"cables\"] == 5), \"cables\"] = 3 # where circuits are \"0\" make \"1\"\n",
    "df_all_lines.loc[df_all_lines[\"circuits\"].isna(), \"circuits\"] = df_all_lines.loc[df_all_lines['circuits'].isna(), \"cables\"] / 3 # one circuit contains 3 cables\n",
    "df_all_lines[\"circuits\"] = df_all_lines[\"circuits\"].astype(int)\n",
    "df_all_lines.loc[(df_all_lines[\"circuits\"] == \"0\") | (df_all_lines[\"circuits\"] == 0), \"circuits\"] = 1 # where circuits are \"0\" make \"1\"\n",
    "\n",
    "if 'cables' in df_all_lines: # drop column if exist\n",
    "    df_all_lines.drop(columns = \"cables\", inplace=True)\n",
    "\n",
    "# df_all_lines[\"circuits\"].unique()\n",
    "# df_all_lines[\"cables\"].unique()\n",
    "# display(df_all_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean voltage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop any row with Voltage = N/A\n",
    "df = df_all_lines.dropna(subset=['voltage']) \n",
    "\n",
    "#Split semicolon separated cells i.e. [66000;220000] and create new identical rows\n",
    "lst_col = 'voltage'\n",
    "x = df.assign(**{lst_col:df[lst_col].str.split(';')})\n",
    "x = pd.DataFrame({\n",
    "    col:np.repeat(x[col].values, x[lst_col].str.len())\n",
    "    for col in x.columns.difference([lst_col])\n",
    "    }).assign(**{lst_col:np.concatenate(x[lst_col].values)})[x.columns.tolist()]\n",
    "df_all_lines = x\n",
    "\n",
    "#display(df_all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique line_id's\n",
    "# The steps below create unique line_id's without loosing the original OSM line_id \n",
    "\n",
    "# Context\n",
    "# The previous duplication of rows (to split the voltage) lead to a couple of same line_id (about 30% of dataset)\n",
    "\n",
    "# Method\n",
    "# Unique line_id are created by simply adding -1,-2,-3 to the original line_id\n",
    "# Every unique id gets a -1 \n",
    "# If a line_id exist i.e. three times it it will the counted by cumcount -1,-2,-3 making the id unique\n",
    "\n",
    "if df_all_lines[\"line_id\"].count() != df_all_lines[\"line_id\"].nunique(): # operate only if line_id is not already unique (nunique counts unique values)\n",
    "    df_all_lines[\"cumcount\"] = df_all_lines.groupby([\"line_id\"]).cumcount() # create cumcount column. Cumcount counts 0,1,2,3 the number of duplicates\n",
    "    df_all_lines[\"cumcount\"] = df_all_lines[\"cumcount\"] + 1 # avoid 0 value for better understanding\n",
    "    df_all_lines[\"line_id\"] = df_all_lines[\"line_id\"].astype(str) + \"-\" + df_all_lines[\"cumcount\"].values.astype(str) # add cumcount to line_id to make line_id unique\n",
    "    df_all_lines.drop(columns = \"cumcount\", inplace=True) # remove cumcount column\n",
    "\n",
    "#display(df_all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/max/anaconda3/envs/pypsa-africa/lib/python3.7/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "# Remove all non-numeric values\n",
    "\n",
    "df_all_lines.loc[:,\"voltage\"] = df_all_lines['voltage'].apply(lambda x: pd.to_numeric(x, errors='coerce')).astype(float) # if cell can't converted to float -> nan\n",
    "df_all_lines = df_all_lines.dropna(subset=['voltage']) # Drop any row with Voltage = N/A\n",
    "df_all_lines.loc[:,\"voltage\"]  = df_all_lines['voltage'].astype(int)\n",
    "#df_all_lines['voltage'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep rows with x > 110 kV as it is considered as transmission level\n",
    "df_all_lines = df_all_lines[df_all_lines.voltage > 110000]\n",
    "\n",
    "# Remove lines that are shorter than 100m\n",
    "#df_all_lines = df_all_lines[df_all_lines.length > 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_all_lines)\n",
    "# display(df_all_lines['voltage'].unique())\n",
    "# display(df_all_lines['length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generate Files (CSV+GeoJSON) \n",
    "\n",
    "\n",
    "### CSV\n",
    "outputfile_partial = os.path.join(os.getcwd(), \"data\", \"clean\", \"africa_all\" + \"_lines\" + \"_clean\") # Output file directory\n",
    "\n",
    "if not os.path.exists(outputfile_partial):\n",
    "    os.makedirs(os.path.dirname(outputfile_partial), exist_ok=True) #  create clean directoryif not already exist\n",
    "    \n",
    "df_all_lines.to_csv(outputfile_partial + \".csv\")  # Generate CSV\n",
    "\n",
    "\n",
    "### GEOJSON\n",
    "df_all_lines = gpd.GeoDataFrame(df_all_lines, geometry=\"geometry\",crs=\"EPSG:4326\")\n",
    "df_all_lines.to_file(outputfile_partial + \".geojson\", driver=\"GeoJSON\")    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Generator -----------\n",
    "\n",
    "#Load uncleaned data\n",
    "df_all_generators = pd.read_csv(os.getcwd()+\"/data/raw/africa_all_raw_generators.csv\")\n",
    "\n",
    "#Clean data\n",
    "df_all_generators = df_all_generators.reset_index(drop=True)\n",
    "df_all_generators = df_all_generators[df_all_generators['tags.generator:output:electricity'].astype(str).str.contains('MW')] #removes boolean \n",
    "df_all_generators['tags.generator:output:electricity'] = df_all_generators['tags.generator:output:electricity'].str.extract('(\\d+)').astype(float)\n",
    "df_all_generators = df_all_generators.rename(columns = {'tags.generator:output:electricity':\"power_output_MW\"})\n",
    "\n",
    "\n",
    "## Generate Files\n",
    "\n",
    "#CSV\n",
    "#outputfile_partial = os.path.join(os.getcwd(),'data','africa_all'+'_generators'+'_cleaned.')\n",
    "#df_all_generators.to_csv(outputfile_partial + 'csv') # Generate CSV\n",
    "\n",
    "#GeoJSON\n",
    "# gdf_generators = convert_pd_to_gdf(df_all_generators)\n",
    "# gdf_generators.to_file(outputfile_partial+'geojson', driver=\"GeoJSON\")  # Generate GeoJson\n",
    "\n",
    "\n",
    "#display(df_all_generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9c13fc6442bf1b8f9598850facaf8fef6fb0663206d3863adab308b8c559389"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('pypsa-africa': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}